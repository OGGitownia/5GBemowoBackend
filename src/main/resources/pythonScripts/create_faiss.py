import faiss
import numpy as np
import sys
import time
from sentence_transformers import SentenceTransformer

# ðŸ”¹ Plik bazy FAISS
FAISS_INDEX_PATH = "faiss_index.idx"

# ðŸ”¹ Model do embedowania tekstu
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

# ðŸ”¹ Markdown plik z normÄ…
MARKDOWN_PATH = "src/main/resources/norms/36331-e60.md"

# ðŸ“Œ Funkcja sprawdzajÄ…ca, czy baza istnieje
def faiss_exists():
    try:
        index = faiss.read_index(FAISS_INDEX_PATH)
        return True
    except:
        return False

# ðŸ“Œ Funkcja do wczytania i przetwarzania Markdown
def process_markdown():
    with open(MARKDOWN_PATH, "r", encoding="utf-8") as f:
        lines = f.readlines()

    # ðŸ”¹ Dzielimy tekst na akapity
    chunks = []
    current_chunk = ""

    for line in lines:
        if line.strip():  # JeÅ›li linia nie jest pusta, dodajemy do fragmentu
            current_chunk += line.strip() + " "
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk = ""

    if current_chunk:
        chunks.append(current_chunk)

    return chunks

# ðŸ“Œ Funkcja tworzÄ…ca FAISS
def create_faiss():
    if faiss_exists():
        print("âœ… Baza FAISS juÅ¼ istnieje.")
        return

    print("ðŸ“¥ Tworzenie FAISS...")

    # ðŸ”¹ Pobieramy fragmenty z Markdown
    chunks = process_markdown()
    embeddings = np.array([embedding_model.encode(chunk) for chunk in chunks])

    # ðŸ”¹ Tworzymy indeks FAISS
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)

    # ðŸ”¹ Zapisujemy FAISS do pliku
    faiss.write_index(index, FAISS_INDEX_PATH)

    print("âœ… Baza FAISS zostaÅ‚a utworzona!")

if __name__ == "__main__":
    # ObsÅ‚uga argumentÃ³w
    if len(sys.argv) > 1 and sys.argv[1] == "check":
        if faiss_exists():
            print("EXISTS")
        else:
            print("NOT_FOUND")
    else:
        create_faiss()
